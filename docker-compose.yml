version: '3.8'

services:
  traefik:
    image: "traefik:v2.10"
    container_name: "traefik"
    command:
      - "--api.insecure=true"
      - "--providers.file.directory=/etc/traefik/conf"
      - "--providers.file.watch=true"
      - "--entrypoints.web.address=:80"
      - "--entrypoints.websecure.address=:443"
      - "--entrypoints.web.http.redirections.entrypoint.to=websecure"
      - "--entrypoints.web.http.redirections.entrypoint.scheme=https"
      - "--certificatesresolvers.letsencrypt.acme.httpchallenge=true"
      - "--certificatesresolvers.letsencrypt.acme.httpchallenge.entrypoint=web"
      - "--certificatesresolvers.letsencrypt.acme.email=${ACME_EMAIL}"
      - "--certificatesresolvers.letsencrypt.acme.storage=/letsencrypt/acme.json"
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - "./reverse-proxy/conf:/etc/traefik/conf:ro"
      - "./reverse-proxy/letsencrypt:/letsencrypt"
    networks:
      - ai-agent-net

  n8n:
    image: n8nio/n8n
    container_name: n8n
    restart: unless-stopped
    environment:
      - NODE_ENV=production
      - N8N_HOST=${N8N_HOST}
      - N8N_ENCRYPTION_KEY=${N8N_ENCRYPTION_KEY}
      - WEBHOOK_URL=${WEBHOOK_URL}
      - GENERIC_TIMEZONE=${GENERIC_TIMEZONE}
      - TELEGRAM_TOKEN=${TELEGRAM_TOKEN}
      - TAVILY_API_KEY=${TAVILY_API_KEY}
      - OLLAMA_MODEL=${OLLAMA_MODEL}
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL}
      - OLLAMA_API_KEY=${OLLAMA_API_KEY}
      - N8N_BLOCK_ENV_ACCESS_IN_NODE=false
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.n8n.rule=Host(`${N8N_HOST}`)"
      - "traefik.http.routers.n8n.entrypoints=websecure"
      - "traefik.http.routers.n8n.tls.certresolver=letsencrypt"
      - "traefik.http.services.n8n.loadbalancer.server.port=5678"
    volumes:
      - ./n8n/data:/home/node/.n8n
    depends_on:
      - ollama
      - chroma
    networks:
      - ai-agent-net
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:5678"]
      interval: 30s
      timeout: 10s
      retries: 5
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: '1.5G'


  ollama:
    image: ollama/ollama
    container_name: ollama
    restart: unless-stopped
    volumes:
      - ./ollama/data:/root/.ollama
    environment:
      # Рекомендуемая компактная модель для слабого ноутбука.
      # Перед первым запуском внутри контейнера выполните:
      #   ollama pull llama3.2:3b
      - OLLAMA_MODEL=${OLLAMA_MODEL}
      # - OLLAMA_MODEL=llama3.1:8b
      # - OLLAMA_MODEL=mistral:7b
    networks:
      - ai-agent-net
    tty: true
    deploy:
      resources:
        limits:
          memory: '8G'  # Увеличим лимит памяти


  chroma:
    image: chromadb/chroma:0.4.24
    container_name: "chroma"
    restart: unless-stopped
    volumes:
      - "./vector-store/data:/chroma/chroma"
    networks:
      - ai-agent-net
    ports: # Exposing is optional, useful for local debugging
      - "8000:8000"
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: '512M'

networks:
  ai-agent-net:
    driver: bridge
