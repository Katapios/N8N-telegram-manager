{
  "name": "Local AI Agent (Cloud-based)",
  "nodes": [
    {
      "parameters": {
        "path": "telegram-ai-agent-cloud",
        "httpMethod": "POST",
        "responseMode": "onReceived",
        "options": {}
      },
      "name": "Webhook",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 1,
      "position": [
        -520,
        300
      ],
      "webhookId": "telegram-ai-agent-cloud"
    },
    {
      "parameters": {
        "functionCode": "const body = $json.body || {};\nconst message = body.message || {};\nconst chat = message.chat || {};\nconst text = (message.text || '').trim();\nconst document = message.document;\n\n// Валидация: проверка наличия chatId\nif (!chat || !chat.id) {\n  throw new Error('Отсутствует chatId в сообщении Telegram');\n}\n\nconst isClear = text === '/clear';\nconst isWebSearch = text.startsWith('/search ');\nconst isDocument = !!document;\nconst query = isClear ? '' : (isWebSearch ? text.replace('/search ', '').trim() : text);\n\n// Проверка на пустой запрос (кроме clear и document)\nif (!isClear && !isDocument && !query) {\n  throw new Error('Пустой запрос. Пожалуйста, отправьте текст или используйте команды /search или /clear.');\n}\n\nreturn [{\n  chatId: chat.id,\n  originalText: text,\n  isWebSearch,\n  isDocument,\n  isClear,\n  document,\n  query\n}];"
      },
      "name": "Parse Telegram",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [
        -300,
        300
      ]
    },
    {
      "parameters": {
        "conditions": {
          "boolean": [
            {
              "value1": "={{ $json.isClear }}",
              "value2": true
            }
          ],
          "string": []
        }
      },
      "name": "If Clear",
      "type": "n8n-nodes-base.if",
      "typeVersion": 1,
      "position": [
        20,
        320
      ]
    },
    {
      "parameters": {
        "requestMethod": "DELETE",
        "url": "http://chroma:8000/api/v1/collections/ai_memory_ollama",
        "jsonParameters": true,
        "options": {
          "ignoreResponseCode": true
        }
      },
      "continueOnFail": true,
      "name": "Clear Collection",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        220,
        140
      ]
    },
    {
      "parameters": {
        "requestMethod": "POST",
        "url": "http://chroma:8000/api/v1/collections",
        "jsonParameters": true,
        "options": {},
        "bodyParametersJson": "{\"name\": \"ai_memory_ollama\", \"get_or_create\": true}"
      },
      "name": "Recreate Collection",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "continueOnFail": true,
      "position": [
        420,
        140
      ]
    },
    {
      "parameters": {
        "chatId": "={{ $('Parse Telegram').first().json.chatId }}",
        "text": "Контекст очищен.",
        "additionalFields": {}
      },
      "name": "Telegram Clear Confirm",
      "type": "n8n-nodes-base.telegram",
      "typeVersion": 1,
      "continueOnFail": true,
      "position": [
        620,
        140
      ],
      "credentials": {
        "telegramApi": {
          "id": "TELEGRAM_CREDENTIALS_ID",
          "name": "Telegram"
        }
      }
    },
    {
      "parameters": {
        "chatId": "={{ $json.chatId }}",
        "text": "Thinking...",
        "additionalFields": {}
      },
      "name": "Telegram Typing",
      "type": "n8n-nodes-base.telegram",
      "typeVersion": 1,
      "continueOnFail": true,
      "position": [
        -90,
        140
      ],
      "credentials": {
        "telegramApi": {
          "id": "TELEGRAM_CREDENTIALS_ID",
          "name": "Telegram"
        }
      }
    },
    {
      "parameters": {
        "conditions": {
          "boolean": [
            {
              "value1": "={{ $json.isDocument }}",
              "value2": true
            }
          ],
          "string": []
        }
      },
      "name": "If Document",
      "type": "n8n-nodes-base.if",
      "typeVersion": 1,
      "position": [
        -90,
        560
      ]
    },
    {
      "parameters": {
        "conditions": {
          "boolean": [
            {
              "value1": "={{ $json.isWebSearch }}",
              "value2": true
            }
          ],
          "string": []
        }
      },
      "name": "If Web Search",
      "type": "n8n-nodes-base.if",
      "typeVersion": 1,
      "position": [
        90,
        420
      ]
    },
    {
      "parameters": {
        "requestMethod": "GET",
        "url": "={{ 'https://api.telegram.org/bot' + $env.TELEGRAM_TOKEN + '/getFile' }}",
        "jsonParameters": true,
        "options": {},
        "sendQuery": true,
        "queryParametersJson": "={{ JSON.stringify({ \"file_id\": $json.document.file_id }) }}"
      },
      "name": "Get File Path",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "continueOnFail": true,
      "position": [
        200,
        700
      ]
    },
    {
      "parameters": {
        "requestMethod": "GET",
        "url": "={{ 'https://api.telegram.org/file/bot' + $env.TELEGRAM_TOKEN + '/' + $json.result.file_path }}",
        "jsonParameters": true,
        "options": {},
        "responseFormat": "string"
      },
      "name": "Download File",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "continueOnFail": true,
      "position": [
        400,
        700
      ]
    },
    {
      "parameters": {
        "functionCode": "const text = $json.data || '';\nconst maxChunk = Number($env.OLLAMA_EMBEDDING_MAX_CHARS) || 2048;\nconst preferredChunk = Math.min(1000, maxChunk);\nconst chunks = [];\nconst paragraphs = text.split(/\\n\\s*\\n/);\nlet currentChunk = '';\nfor (const pRaw of paragraphs) {\n  const p = pRaw.trim();\n  if (!p) continue;\n  if (p.length > maxChunk) {\n    if (currentChunk) {\n      chunks.push(currentChunk.trim());\n      currentChunk = '';\n    }\n    for (let i = 0; i < p.length; i += maxChunk) {\n      chunks.push(p.slice(i, i + maxChunk));\n    }\n    continue;\n  }\n  const separator = currentChunk ? '\\n\\n' : '';\n  if ((currentChunk + separator + p).length > preferredChunk) {\n    if (currentChunk) chunks.push(currentChunk.trim());\n    currentChunk = p;\n  } else {\n    currentChunk += separator + p;\n  }\n}\nif (currentChunk) chunks.push(currentChunk.trim());\nif (chunks.length === 0 && text.length > 0) {\n  for (let i = 0; i < text.length; i += maxChunk) {\n    chunks.push(text.slice(i, i + maxChunk));\n  }\n}\nconst safeChunks = chunks.map((chunk) => chunk.slice(0, maxChunk)).filter((chunk) => chunk.length > 0);\n\nconst overlap = Math.min(200, Math.floor(preferredChunk * 0.2));\nconst overlapped = [];\nfor (let i = 0; i < safeChunks.length; i++) {\n  const cur = safeChunks[i];\n  if (i === 0 || overlap <= 0) {\n    overlapped.push(cur);\n    continue;\n  }\n  const prev = safeChunks[i - 1];\n  const prefix = prev.slice(-overlap);\n  let merged = (prefix + '\\n' + cur);\n  if (merged.length > maxChunk) {\n    merged = merged.slice(merged.length - maxChunk);\n  }\n  overlapped.push(merged);\n}\nreturn overlapped.map((chunk, index) => ({\n  chunk,\n  chunkIndex: index,\n  totalChunks: overlapped.length,\n  fileName: $node[\"Parse Telegram\"].json.document.file_name,\n  chatId: $node[\"Parse Telegram\"].json.chatId\n}));"
      },
      "name": "Split Text",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [
        600,
        700
      ]
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "chunk_data",
              "name": "chunkData",
              "value": "={{ $json }}",
              "type": "object"
            }
          ]
        },
        "options": {}
      },
      "name": "Store Chunk Data",
      "type": "n8n-nodes-base.set",
      "typeVersion": 3,
      "position": [
        700,
        700
      ]
    },
    {
      "parameters": {
        "requestMethod": "POST",
        "url": "={{ ($env.OLLAMA_BASE_URL || 'http://ollama:11434') + '/api/embeddings' }}",
        "jsonParameters": true,
        "options": {},
        "headerParameters": [
          {
            "name": "Authorization",
            "value": "={{ $env.OLLAMA_API_KEY ? ('Bearer ' + $env.OLLAMA_API_KEY) : '' }}"
          }
        ],
        "bodyParametersJson": "={{ JSON.stringify({\n  \"model\": ($env.OLLAMA_EMBEDDING_MODEL || \"nomic-embed-text\"),\n  \"prompt\": ($json.chunk || '').substring(0, (Number($env.OLLAMA_EMBEDDING_MAX_CHARS) || 2048))\n}) }}"
      },
      "name": "OpenAI Embed Chunk",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "continueOnFail": true,
      "position": [
        800,
        700
      ]
    },
    {
      "parameters": {
        "functionCode": "// Получаем ответ от Ollama API (текущий элемент)\nconst ollamaResponse = $json;\n\n// Извлекаем embedding из ответа Ollama\nlet embedding = null;\ntry {\n  if (ollamaResponse.embedding && Array.isArray(ollamaResponse.embedding)) {\n    embedding = ollamaResponse.embedding;\n  } else if (ollamaResponse.data && Array.isArray(ollamaResponse.data) && ollamaResponse.data[0] && ollamaResponse.data[0].embedding) {\n    embedding = ollamaResponse.data[0].embedding;\n  } else if (Array.isArray(ollamaResponse)) {\n    embedding = ollamaResponse;\n  }\n} catch (e) {\n  console.error('Ошибка извлечения embedding:', e);\n}\n\nif (!embedding || !Array.isArray(embedding) || embedding.length === 0) {\n  throw new Error('Не удалось извлечь embedding из ответа Ollama. Ответ: ' + JSON.stringify(ollamaResponse));\n}\n\n// Получаем данные чанка из узла Store Chunk Data\n// В n8n, когда элементы обрабатываются последовательно, они имеют одинаковый индекс\n// Используем $input.all() для получения данных из всех входных соединений\nlet chunkData = null;\n\ntry {\n  // Получаем все входные данные\n  const allInputs = $input.all();\n  \n  // Ищем данные чанка во всех входах\n  // Данные из Store Chunk Data должны быть в одном из входов\n  for (const batch of allInputs) {\n    for (const item of batch) {\n      if (item.json) {\n        // Проверяем chunkData (данные из Set узла)\n        if (item.json.chunkData && item.json.chunkData.chunk) {\n          chunkData = item.json.chunkData;\n          break;\n        }\n        // Или проверяем chunk напрямую\n        else if (item.json.chunk && item.json.chunkIndex !== undefined) {\n          chunkData = item.json;\n          break;\n        }\n      }\n    }\n    if (chunkData) break;\n  }\n  \n  // Если не нашли через $input.all(), пробуем через $('Store Chunk Data')\n  if (!chunkData) {\n    try {\n      const storedAll = $('Store Chunk Data').all();\n      if (storedAll && storedAll.length > 0 && storedAll[0].length > 0) {\n        // Находим индекс текущего элемента\n        // В n8n элементы обрабатываются последовательно\n        const currentInputs = $input.all();\n        let currentIndex = 0;\n        \n        // Пытаемся найти индекс текущего элемента\n        for (let i = 0; i < currentInputs.length; i++) {\n          const batch = currentInputs[i];\n          for (let j = 0; j < batch.length; j++) {\n            if (batch[j].json === ollamaResponse || (batch[j].json.embedding && Array.isArray(batch[j].json.embedding))) {\n              currentIndex = j;\n              break;\n            }\n          }\n        }\n        \n        const firstBatch = storedAll[0];\n        if (firstBatch && firstBatch[currentIndex] && firstBatch[currentIndex].json) {\n          const storedItem = firstBatch[currentIndex].json;\n          if (storedItem.chunkData) {\n            chunkData = storedItem.chunkData;\n          } else if (storedItem.chunk) {\n            chunkData = storedItem;\n          }\n        }\n        \n        // Fallback: берем первый элемент\n        if (!chunkData && firstBatch[0] && firstBatch[0].json) {\n          const firstItem = firstBatch[0].json;\n          if (firstItem.chunkData) {\n            chunkData = firstItem.chunkData;\n          } else if (firstItem.chunk) {\n            chunkData = firstItem;\n          }\n        }\n      }\n    } catch (e) {\n      console.error('Ошибка получения через $():', e);\n    }\n  }\n  \n} catch (e) {\n  console.error('Общая ошибка получения данных чанка:', e);\n}\n\nif (!chunkData || !chunkData.chunk) {\n  throw new Error('Не удалось получить данные чанка. Проверьте соединения между узлами Store Chunk Data и Extract Chunk Embedding.');\n}\n\nreturn [{\n  embedding: embedding,\n  chunk: chunkData.chunk,\n  chunkIndex: chunkData.chunkIndex,\n  totalChunks: chunkData.totalChunks,\n  fileName: chunkData.fileName,\n  chatId: chunkData.chatId\n}];"
      },
      "name": "Extract Chunk Embedding",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [
        900,
        700
      ]
    },
    {
      "parameters": {
        "requestMethod": "POST",
        "url": "={{ 'http://chroma:8000/api/v1/collections/' + $('Merge Collection ID').first().json.collectionId + '/upsert' }}",
        "jsonParameters": true,
        "options": {},
        "bodyParametersJson": "={{ JSON.stringify({\n  \"ids\": [ $('Parse Telegram').first().json.document.file_id + \"_\" + $json.chunkIndex ],\n  \"embeddings\": [ $json.embedding ],\n  \"documents\": [ $json.chunk ],\n  \"metadatas\": [ { \"source\": \"file\", \"filename\": $json.fileName, \"chatId\": $json.chatId } ]\n}) }}"
      },
      "name": "Upsert Chunk",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "continueOnFail": true,
      "position": [
        1000,
        700
      ]
    },
    {
      "parameters": {
        "chatId": "={{ $('Parse Telegram').first().json.chatId }}",
        "text": "={{ 'I have read \"' + $('Parse Telegram').first().json.document.file_name + '\". Processed ' + ($('Split Text').item.json.chunkIndex + 1) + ' of ' + $('Split Text').item.json.totalChunks + ' chunks.' }}",
        "additionalFields": {}
      },
      "name": "Notify Progress",
      "type": "n8n-nodes-base.telegram",
      "typeVersion": 1,
      "continueOnFail": true,
      "position": [
        1200,
        700
      ],
      "credentials": {
        "telegramApi": {
          "id": "TELEGRAM_CREDENTIALS_ID",
          "name": "Telegram"
        }
      }
    },
    {
      "parameters": {
        "requestMethod": "POST",
        "url": "http://chroma:8000/api/v1/collections",
        "jsonParameters": true,
        "options": {},
        "bodyParametersJson": "{\"name\": \"ai_memory_ollama\", \"get_or_create\": true}"
      },
      "name": "Get Collection",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "continueOnFail": true,
      "position": [
        -200,
        420
      ]
    },
    {
      "parameters": {
        "functionCode": "const original = $node[\"Parse Telegram\"].json;\nconst collection = $json;\nif (!collection || !collection.id) {\n  throw new Error('Не удалось получить или создать коллекцию ChromaDB');\n}\nreturn [{ ...original, collectionId: collection.id }];"
      },
      "name": "Merge Collection ID",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [
        200,
        420
      ]
    },
    {
      "parameters": {
        "requestMethod": "POST",
        "url": "={{ ($env.OLLAMA_BASE_URL || 'http://ollama:11434') + '/api/embeddings' }}",
        "jsonParameters": true,
        "options": {},
        "headerParameters": [
          {
            "name": "Authorization",
            "value": "={{ $env.OLLAMA_API_KEY ? ('Bearer ' + $env.OLLAMA_API_KEY) : '' }}"
          }
        ],
        "bodyParametersJson": "={{ JSON.stringify({\n  \"model\": ($env.OLLAMA_EMBEDDING_MODEL || \"nomic-embed-text\"),\n  \"prompt\": (($json.query || '')).substring(0, (Number($env.OLLAMA_EMBEDDING_MAX_CHARS) || 2048))\n}) }}"
      },
      "name": "OpenAI Generate Query Embedding",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "continueOnFail": true,
      "position": [
        140,
        220
      ]
    },
    {
      "parameters": {
        "functionCode": "const resp = $json;\nlet embedding = null;\n\ntry {\n  // Ollama API возвращает embedding в поле 'embedding'\n  if (resp.embedding && Array.isArray(resp.embedding)) {\n    embedding = resp.embedding;\n  } else if (resp.data && Array.isArray(resp.data) && resp.data[0] && resp.data[0].embedding) {\n    embedding = resp.data[0].embedding;\n  } else if (Array.isArray(resp)) {\n    embedding = resp;\n  }\n} catch (e) {\n  console.error('Ошибка извлечения query embedding:', e);\n}\n\nif (!embedding || !Array.isArray(embedding) || embedding.length === 0) {\n  throw new Error('Не удалось извлечь embedding запроса из ответа Ollama. Ответ: ' + JSON.stringify(resp));\n}\n\n// Сохраняем данные из предыдущих узлов\nconst originalData = $node['Merge Collection ID'].json;\n\nreturn [{\n  embedding: embedding,\n  collectionId: originalData.collectionId,\n  chatId: originalData.chatId,\n  query: originalData.query,\n  originalText: originalData.originalText,\n  isWebSearch: originalData.isWebSearch\n}];"
      },
      "name": "Extract Query Embedding",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [
        240,
        220
      ]
    },
    {
      "parameters": {
        "requestMethod": "POST",
        "url": "={{ 'http://chroma:8000/api/v1/collections/' + $json.collectionId + '/query' }}",
        "jsonParameters": true,
        "options": {},
        "bodyParametersJson": "={{ JSON.stringify({ \"query_embeddings\": [ $json.embedding ], \"n_results\": 10, \"where\": { \"chatId\": $json.chatId } }) }}"
      },
      "name": "Chroma Query",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "continueOnFail": true,
      "position": [
        340,
        220
      ]
    },
    {
      "parameters": {
        "functionCode": "const results = $json.documents || [];\nlet context = '';\ntry {\n  if (Array.isArray(results) && results.length > 0) {\n    const docs = results[0];\n    if (Array.isArray(docs) && docs.length > 0) {\n      context = docs.filter(d => d && d.trim()).join('\\n\\n');\n    }\n  }\n} catch (e) {\n  console.error('Ошибка обработки результатов Chroma:', e);\n  context = '';\n}\n\nconst originalData = $('Parse Telegram').first().json;\nif (!originalData || !originalData.chatId) {\n  throw new Error('Отсутствуют данные из Parse Telegram');\n}\n\nreturn [{\n  chatId: originalData.chatId,\n  originalText: originalData.originalText || '',\n  query: originalData.query || '',\n  isWebSearch: originalData.isWebSearch || false,\n  memoryContext: context\n}];"
      },
      "name": "Build RAG Context",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [
        440,
        220
      ]
    },
    {
      "parameters": {
        "requestMethod": "POST",
        "url": "https://api.tavily.com/search",
        "jsonParameters": true,
        "options": {},
        "bodyParametersJson": "={{ JSON.stringify({\n  \"api_key\": $env.TAVILY_API_KEY,\n  \"query\": $json.query,\n  \"search_depth\": \"advanced\",\n  \"max_results\": 7,\n  \"include_answer\": true,\n  \"include_raw_content\": true\n}) }}"
      },
      "name": "Tavily Search",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "continueOnFail": true,
      "position": [
        140,
        520
      ]
    },
    {
      "parameters": {
        "functionCode": "let webContext = '';\ntry {\n  if ($json && $json.answer && $json.answer.trim()) {\n    webContext += `Tavily Direct Answer:\\n${$json.answer.trim()}\\n\\n`;\n  }\n  \n  const results = Array.isArray($json.results) ? $json.results.slice(0, 3) : [];\n  if (results.length > 0) {\n    webContext += \"Search Results:\\n\";\n    webContext += results\n      .filter(r => r && (r.title || r.content))\n      .map((r, i) => {\n        const title = r.title || 'Без названия';\n        const url = r.url || '';\n        const content = (r.content || '').slice(0, 800);\n        return `[${i+1}] Title: ${title}\\n${url ? 'URL: ' + url + '\\n' : ''}Content: ${content}`;\n      })\n      .join('\\n\\n');\n  }\n} catch (e) {\n  console.error('Ошибка обработки результатов Tavily:', e);\n  webContext = '';\n}\n\nconst originalData = $('Parse Telegram').first().json;\nif (!originalData || !originalData.chatId) {\n  throw new Error('Отсутствуют данные из Parse Telegram');\n}\n\nreturn [{\n  chatId: originalData.chatId,\n  originalText: originalData.originalText || '',\n  query: originalData.query || '',\n  memoryContext: '',\n  webContext: webContext.trim()\n}];"
      },
      "name": "Build Web Context",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [
        360,
        520
      ]
    },
    {
      "parameters": {
        "functionCode": "const system = 'Ты русскоязычный AI-ассистент в Telegram. Твоя задача - давать точные, полезные и структурированные ответы.\\n\\nИнструкции:\\n1. Используй контекст из памяти (Memory) и веб-поиска (Web) для полноты ответа\\n2. Проверяй факты по предоставленному контексту\\n3. Указывай источники в формате [1], [2] при использовании контекста\\n4. Если контекста недостаточно, используй свои знания, но укажи это\\n5. Отвечай развернуто и по делу, с примерами и шагами\\n6. Форматируй ответ для удобства чтения (используй списки, абзацы)\\n7. Если вопрос неясен, уточни что именно нужно';\n\nconst parts = [];\nif ($json.memoryContext && $json.memoryContext.trim()) {\n  parts.push('Memory context (из прошлых разговоров и документов):\\n' + $json.memoryContext.trim());\n}\nif ($json.webContext && $json.webContext.trim()) {\n  parts.push('Web search context (актуальная информация из интернета):\\n' + $json.webContext.trim());\n}\n\nconst MAX_CTX = Number($env.OLLAMA_PROMPT_MAX_CHARS) || 12000;\nlet context = parts.join('\\n\\n');\nif (context.length > MAX_CTX) {\n  context = context.slice(0, MAX_CTX) + '... [контекст обрезан]';\n}\n\nlet content = '';\nif (context) {\n  content = '<<CONTEXT_START>>\\n' + context + '\\n<<CONTEXT_END>>\\n\\nВопрос: ' + ($json.query || 'Без вопроса') + '\\nОтвет:';\n} else {\n  content = 'Вопрос: ' + ($json.query || 'Без вопроса') + '\\nОтвет:';\n}\n\nif (!$json.chatId) {\n  throw new Error('Отсутствует chatId');\n}\n\nreturn [{ chatId: $json.chatId, prompt: content, system, query: $json.query || '' }];"
      },
      "name": "Build Prompt",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [
        580,
        340
      ]
    },
    {
      "parameters": {
        "requestMethod": "POST",
        "url": "={{ ($env.OLLAMA_BASE_URL || 'http://ollama:11434') + '/api/chat' }}",
        "jsonParameters": true,
        "options": {},
        "headerParameters": [
          {
            "name": "Authorization",
            "value": "={{ $env.OLLAMA_API_KEY ? ('Bearer ' + $env.OLLAMA_API_KEY) : '' }}"
          }
        ],
        "bodyParametersJson": "={{ JSON.stringify({\n  \"model\": ($env.OLLAMA_MODEL || \"qwen3-coder:480b-cloud\"),\n  \"keep_alive\": \"30m\",\n  \"stream\": false,\n  \"options\": { \"temperature\": 0 },\n  \"messages\": [\n    {\"role\": \"system\", \"content\": $json.system},\n    {\"role\": \"user\", \"content\": $json.prompt}\n  ]\n}) }}"
      },
      "name": "Ollama Chat",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "continueOnFail": true,
      "position": [
        800,
        340
      ]
    },
    {
      "parameters": {
        "functionCode": "const resp = $json;\nlet llmAnswer = '';\ntry {\n  if (resp.message && resp.message.content) {\n    llmAnswer = String(resp.message.content).trim();\n  } else if (resp.choices && resp.choices[0] && resp.choices[0].message && resp.choices[0].message.content) {\n    llmAnswer = String(resp.choices[0].message.content).trim();\n  } else if (typeof resp === 'string') {\n    llmAnswer = resp.trim();\n  }\n} catch (e) {\n  console.error('Ошибка извлечения ответа:', e);\n}\n\nif (!llmAnswer) {\n  if (resp.error) {\n    llmAnswer = 'Ошибка от AI: ' + (typeof resp.error === 'string' ? resp.error : JSON.stringify(resp.error));\n  } else {\n    llmAnswer = 'Не удалось получить ответ от AI. Попробуйте еще раз.';\n  }\n}\n\nlet tavilyAnswer = '';\ntry {\n  const t = $('Tavily Search').first()?.json;\n  if (t && t.answer) {\n    tavilyAnswer = String(t.answer).trim();\n  }\n} catch (e) {\n  // Tavily не обязателен, игнорируем ошибку\n}\n\n// Объединяем ответы, избегая дублирования\nlet finalAnswer = '';\nif (tavilyAnswer && llmAnswer) {\n  // Если Tavily дал прямой ответ, используем его как основной, LLM как дополнение\n  if (tavilyAnswer.length > 100) {\n    finalAnswer = tavilyAnswer + '\\n\\n---\\n\\nДополнительная информация:\\n' + llmAnswer;\n  } else {\n    finalAnswer = llmAnswer;\n  }\n} else if (tavilyAnswer) {\n  finalAnswer = tavilyAnswer;\n} else {\n  finalAnswer = llmAnswer;\n}\n\nconst originalData = $('Parse Telegram').first().json;\nconst promptData = $('Build Prompt').first()?.json || {};\n\nif (!originalData || !originalData.chatId) {\n  throw new Error('Отсутствует chatId для отправки ответа');\n}\n\nreturn [{ chatId: originalData.chatId, answer: finalAnswer, question: promptData.query || originalData.query || '' }];"
      },
      "name": "Extract Answer",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [
        1020,
        340
      ]
    },
    {
      "parameters": {
        "requestMethod": "POST",
        "url": "={{ ($env.OLLAMA_BASE_URL || 'http://ollama:11434') + '/api/embeddings' }}",
        "jsonParameters": true,
        "options": {},
        "headerParameters": [
          {
            "name": "Authorization",
            "value": "={{ $env.OLLAMA_API_KEY ? ('Bearer ' + $env.OLLAMA_API_KEY) : '' }}"
          }
        ],
        "bodyParametersJson": "={{ JSON.stringify({\n  \"model\": ($env.OLLAMA_EMBEDDING_MODEL || \"nomic-embed-text\"),\n  \"prompt\": (($json.question || '') + \"\\n\\n\" + ($json.answer || '')).substring(0, (Number($env.OLLAMA_EMBEDDING_MAX_CHARS) || 2048))\n}) }}"
      },
      "name": "OpenAI Generate Answer Embedding",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "continueOnFail": true,
      "position": [
        1240,
        220
      ]
    },
    {
      "parameters": {
        "functionCode": "const resp = $json;\nlet embedding = null;\n\ntry {\n  // Ollama API возвращает embedding в поле 'embedding'\n  if (resp.embedding && Array.isArray(resp.embedding)) {\n    embedding = resp.embedding;\n  } else if (resp.data && Array.isArray(resp.data) && resp.data[0] && resp.data[0].embedding) {\n    embedding = resp.data[0].embedding;\n  } else if (Array.isArray(resp)) {\n    embedding = resp;\n  }\n} catch (e) {\n  console.error('Ошибка извлечения answer embedding:', e);\n}\n\nif (!embedding || !Array.isArray(embedding) || embedding.length === 0) {\n  // Не критично, просто пропускаем сохранение\n  return [];\n}\n\n// Сохраняем данные из предыдущих узлов\nconst answerData = $node['Extract Answer'].json;\nconst collectionData = $node['Merge Collection ID'].json;\n\nreturn [{\n  embedding: embedding,\n  collectionId: collectionData.collectionId,\n  question: answerData.question,\n  answer: answerData.answer\n}];"
      },
      "name": "Extract Answer Embedding",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "continueOnFail": true,
      "position": [
        1340,
        220
      ]
    },
    {
      "parameters": {
        "requestMethod": "POST",
        "url": "={{ 'http://chroma:8000/api/v1/collections/' + $json.collectionId + '/upsert' }}",
        "jsonParameters": true,
        "options": {},
        "bodyParametersJson": "={{ JSON.stringify({\n  \"ids\": [ Date.now().toString() ],\n  \"embeddings\": [ $json.embedding ],\n  \"documents\": [ $json.question + \"\\n\\n\" + $json.answer ],\n  \"metadatas\": [ { \"source\": \"telegram\", \"chatId\": $json.chatId } ]\n}) }}"
      },
      "name": "Chroma Upsert",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "continueOnFail": true,
      "position": [
        1440,
        220
      ]
    },
    {
      "parameters": {
        "functionCode": "const answer = $json.answer || '';\nconst modelName = $env.OLLAMA_MODEL || 'unknown';\nconst prefix = `[${modelName}] `;\nconst fullText = prefix + answer;\n\n// Telegram лимит: 4096 символов на сообщение\nconst MAX_LENGTH = 4096;\nconst PREFIX_LENGTH = prefix.length;\nconst ACTUAL_MAX = MAX_LENGTH - PREFIX_LENGTH - 50; // Запас для безопасности\n\nif (fullText.length <= MAX_LENGTH) {\n  return [{ chatId: $json.chatId, text: fullText, partIndex: 0, totalParts: 1 }];\n}\n\n// Разбиваем на части\nconst parts = [];\nlet remaining = answer;\nlet partIndex = 0;\n\nwhile (remaining.length > 0) {\n  if (remaining.length <= ACTUAL_MAX) {\n    parts.push({\n      chatId: $json.chatId,\n      text: partIndex === 0 ? prefix + remaining : `[${partIndex + 1}/${parts.length + 1}] ${remaining}`,\n      partIndex: partIndex,\n      totalParts: parts.length + 1\n    });\n    break;\n  }\n  \n  // Пытаемся разбить по предложениям\n  let chunk = remaining.slice(0, ACTUAL_MAX);\n  const lastPeriod = chunk.lastIndexOf('. ');\n  const lastNewline = chunk.lastIndexOf('\\n');\n  const splitPoint = Math.max(lastPeriod, lastNewline);\n  \n  if (splitPoint > ACTUAL_MAX * 0.7) {\n    chunk = remaining.slice(0, splitPoint + 1);\n    remaining = remaining.slice(splitPoint + 1).trim();\n  } else {\n    // Принудительный разрез\n    chunk = remaining.slice(0, ACTUAL_MAX);\n    remaining = remaining.slice(ACTUAL_MAX).trim();\n  }\n  \n  parts.push({\n    chatId: $json.chatId,\n    text: partIndex === 0 ? prefix + chunk : `[${partIndex + 1}/${parts.length + 1}] ${chunk}`,\n    partIndex: partIndex,\n    totalParts: 0 // Обновим позже\n  });\n  \n  partIndex++;\n}\n\n// Обновляем totalParts\nconst totalParts = parts.length;\nreturn parts.map((p, idx) => ({\n  ...p,\n  totalParts: totalParts,\n  text: idx === 0 ? p.text : p.text.replace(/\\[\\d+\\/\\d+\\]/, `[${idx + 1}/${totalParts}]`)\n}));"
      },
      "name": "Split Long Message",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [
        1440,
        460
      ]
    },
    {
      "parameters": {
        "chatId": "={{ $json.chatId }}",
        "text": "={{ $json.text }}",
        "additionalFields": {}
      },
      "name": "Telegram Send Answer",
      "type": "n8n-nodes-base.telegram",
      "typeVersion": 1,
      "continueOnFail": true,
      "position": [
        1640,
        460
      ],
      "credentials": {
        "telegramApi": {
          "id": "TELEGRAM_CREDENTIALS_ID",
          "name": "Telegram"
        }
      }
    }
  ],
  "connections": {
    "Webhook": {
      "main": [
        [
          {
            "node": "Parse Telegram",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Parse Telegram": {
      "main": [
        [
          {
            "node": "Telegram Typing",
            "type": "main",
            "index": 0
          },
          {
            "node": "Get Collection",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Get Collection": {
      "main": [
        [
          {
            "node": "Merge Collection ID",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge Collection ID": {
      "main": [
        [
          {
            "node": "If Clear",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "If Clear": {
      "main": [
        [
          {
            "node": "Clear Collection",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "If Document",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Clear Collection": {
      "main": [
        [
          {
            "node": "Recreate Collection",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Recreate Collection": {
      "main": [
        [
          {
            "node": "Telegram Clear Confirm",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "If Document": {
      "main": [
        [
          {
            "node": "Get File Path",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "If Web Search",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "If Web Search": {
      "main": [
        [
          {
            "node": "Tavily Search",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "OpenAI Generate Query Embedding",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Generate Query Embedding": {
      "main": [
        [
          {
            "node": "Extract Query Embedding",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract Query Embedding": {
      "main": [
        [
          {
            "node": "Chroma Query",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Chroma Query": {
      "main": [
        [
          {
            "node": "Build RAG Context",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Tavily Search": {
      "main": [
        [
          {
            "node": "Build Web Context",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Build RAG Context": {
      "main": [
        [
          {
            "node": "Build Prompt",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Build Web Context": {
      "main": [
        [
          {
            "node": "Build Prompt",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Build Prompt": {
      "main": [
        [
          {
            "node": "Ollama Chat",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Ollama Chat": {
      "main": [
        [
          {
            "node": "Extract Answer",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract Answer": {
      "main": [
        [
          {
            "node": "OpenAI Generate Answer Embedding",
            "type": "main",
            "index": 0
          },
          {
            "node": "Split Long Message",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Split Long Message": {
      "main": [
        [
          {
            "node": "Telegram Send Answer",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Generate Answer Embedding": {
      "main": [
        [
          {
            "node": "Extract Answer Embedding",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract Answer Embedding": {
      "main": [
        [
          {
            "node": "Chroma Upsert",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Get File Path": {
      "main": [
        [
          {
            "node": "Download File",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Download File": {
      "main": [
        [
          {
            "node": "Split Text",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Split Text": {
      "main": [
        [
          {
            "node": "Store Chunk Data",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Store Chunk Data": {
      "main": [
        [
          {
            "node": "OpenAI Embed Chunk",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Embed Chunk": {
      "main": [
        [
          {
            "node": "Extract Chunk Embedding",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract Chunk Embedding": {
      "main": [
        [
          {
            "node": "Upsert Chunk",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Upsert Chunk": {
      "main": [
        [
          {
            "node": "Notify Progress",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "pinData": {}
}